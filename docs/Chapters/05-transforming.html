<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>5&nbsp; Transforming your Spark DataFrame - Part 1 – Introduction to `pyspark`</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../Chapters/07-import.html" rel="next">
<link href="../Chapters/04-columns.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-G42L33VM26"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-G42L33VM26', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Introduction to <code>pyspark</code></span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://pedro-faria.netlify.app/"> 
<span class="menu-text">Visit the author’s blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pedropark99/Introd-pyspark"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../Chapters/05-transforming.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transforming your Spark DataFrame - Part 1</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/02-python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Key concepts of python</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/03-spark.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introducing Apache Spark</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/04-dataframes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introducing Spark DataFrames</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/04-columns.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing the <code>Column</code> class</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/05-transforming.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transforming your Spark DataFrame - Part 1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/07-import.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Importing data to Spark</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/06-dataframes-sql.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Working with SQL in <code>pyspark</code></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/08-transforming2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Transforming your Spark DataFrame - Part 2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/07-export.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Exporting data out of Spark</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/09-strings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Tools for string manipulation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/10-datetime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Tools for dates and datetimes manipulation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/11-window.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introducing window functions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-df-defining-transformations" id="toc-sec-df-defining-transformations" class="nav-link active" data-scroll-target="#sec-df-defining-transformations"><span class="header-section-number">5.1</span> Defining transformations</a></li>
  <li><a href="#sec-dataframe-actions" id="toc-sec-dataframe-actions" class="nav-link" data-scroll-target="#sec-dataframe-actions"><span class="header-section-number">5.2</span> Triggering calculations with actions</a></li>
  <li><a href="#sec-narrow-wide" id="toc-sec-narrow-wide" class="nav-link" data-scroll-target="#sec-narrow-wide"><span class="header-section-number">5.3</span> Understanding narrow and wide transformations</a></li>
  <li><a href="#sec-transf-dataframe" id="toc-sec-transf-dataframe" class="nav-link" data-scroll-target="#sec-transf-dataframe"><span class="header-section-number">5.4</span> The <code>transf</code> DataFrame</a></li>
  <li><a href="#filtering-rows-of-your-dataframe" id="toc-filtering-rows-of-your-dataframe" class="nav-link" data-scroll-target="#filtering-rows-of-your-dataframe"><span class="header-section-number">5.5</span> Filtering rows of your DataFrame</a>
  <ul class="collapse">
  <li><a href="#logical-operators-available" id="toc-logical-operators-available" class="nav-link" data-scroll-target="#logical-operators-available"><span class="header-section-number">5.5.1</span> Logical operators available</a></li>
  <li><a href="#connecting-multiple-logical-expressions" id="toc-connecting-multiple-logical-expressions" class="nav-link" data-scroll-target="#connecting-multiple-logical-expressions"><span class="header-section-number">5.5.2</span> Connecting multiple logical expressions</a></li>
  <li><a href="#translating-the-in-keyword-to-the-pythonic-way" id="toc-translating-the-in-keyword-to-the-pythonic-way" class="nav-link" data-scroll-target="#translating-the-in-keyword-to-the-pythonic-way"><span class="header-section-number">5.5.3</span> Translating the <code>in</code> keyword to the pythonic way</a></li>
  <li><a href="#negating-logical-conditions" id="toc-negating-logical-conditions" class="nav-link" data-scroll-target="#negating-logical-conditions"><span class="header-section-number">5.5.4</span> Negating logical conditions</a></li>
  <li><a href="#sec-filter-null-values" id="toc-sec-filter-null-values" class="nav-link" data-scroll-target="#sec-filter-null-values"><span class="header-section-number">5.5.5</span> Filtering <code>null</code> values (i.e.&nbsp;missing data)</a></li>
  <li><a href="#filtering-dates-and-datetimes-in-your-dataframe" id="toc-filtering-dates-and-datetimes-in-your-dataframe" class="nav-link" data-scroll-target="#filtering-dates-and-datetimes-in-your-dataframe"><span class="header-section-number">5.5.6</span> Filtering dates and datetimes in your DataFrame</a></li>
  <li><a href="#sec-filter-pattern-search" id="toc-sec-filter-pattern-search" class="nav-link" data-scroll-target="#sec-filter-pattern-search"><span class="header-section-number">5.5.7</span> Searching for a particular pattern in string values</a></li>
  </ul></li>
  <li><a href="#selecting-a-subset-of-rows-from-your-dataframe" id="toc-selecting-a-subset-of-rows-from-your-dataframe" class="nav-link" data-scroll-target="#selecting-a-subset-of-rows-from-your-dataframe"><span class="header-section-number">5.6</span> Selecting a subset of rows from your DataFrame</a>
  <ul class="collapse">
  <li><a href="#limiting-the-number-of-rows-in-your-dataframe" id="toc-limiting-the-number-of-rows-in-your-dataframe" class="nav-link" data-scroll-target="#limiting-the-number-of-rows-in-your-dataframe"><span class="header-section-number">5.6.1</span> Limiting the number of rows in your DataFrame</a></li>
  <li><a href="#getting-the-firstlast-n-rows-of-your-dataframe" id="toc-getting-the-firstlast-n-rows-of-your-dataframe" class="nav-link" data-scroll-target="#getting-the-firstlast-n-rows-of-your-dataframe"><span class="header-section-number">5.6.2</span> Getting the first/last <span class="math inline">\(n\)</span> rows of your DataFrame</a></li>
  <li><a href="#taking-a-random-sample-of-your-dataframe" id="toc-taking-a-random-sample-of-your-dataframe" class="nav-link" data-scroll-target="#taking-a-random-sample-of-your-dataframe"><span class="header-section-number">5.6.3</span> Taking a random sample of your DataFrame</a></li>
  </ul></li>
  <li><a href="#managing-the-columns-of-your-dataframe" id="toc-managing-the-columns-of-your-dataframe" class="nav-link" data-scroll-target="#managing-the-columns-of-your-dataframe"><span class="header-section-number">5.7</span> Managing the columns of your DataFrame</a>
  <ul class="collapse">
  <li><a href="#renaming-your-columns" id="toc-renaming-your-columns" class="nav-link" data-scroll-target="#renaming-your-columns"><span class="header-section-number">5.7.1</span> Renaming your columns</a></li>
  <li><a href="#dropping-unnecessary-columns" id="toc-dropping-unnecessary-columns" class="nav-link" data-scroll-target="#dropping-unnecessary-columns"><span class="header-section-number">5.7.2</span> Dropping unnecessary columns</a></li>
  <li><a href="#sec-cast-column-type" id="toc-sec-cast-column-type" class="nav-link" data-scroll-target="#sec-cast-column-type"><span class="header-section-number">5.7.3</span> Casting columns to a different data type</a></li>
  <li><a href="#you-can-add-new-columns-with-select" id="toc-you-can-add-new-columns-with-select" class="nav-link" data-scroll-target="#you-can-add-new-columns-with-select"><span class="header-section-number">5.7.4</span> You can add new columns with <code>select()</code></a></li>
  </ul></li>
  <li><a href="#calculating-or-adding-new-columns-to-your-dataframe" id="toc-calculating-or-adding-new-columns-to-your-dataframe" class="nav-link" data-scroll-target="#calculating-or-adding-new-columns-to-your-dataframe"><span class="header-section-number">5.8</span> Calculating or adding new columns to your DataFrame</a></li>
  <li><a href="#sorting-rows-of-your-dataframe" id="toc-sorting-rows-of-your-dataframe" class="nav-link" data-scroll-target="#sorting-rows-of-your-dataframe"><span class="header-section-number">5.9</span> Sorting rows of your DataFrame</a></li>
  <li><a href="#calculating-aggregates" id="toc-calculating-aggregates" class="nav-link" data-scroll-target="#calculating-aggregates"><span class="header-section-number">5.10</span> Calculating aggregates</a>
  <ul class="collapse">
  <li><a href="#using-standard-dataframe-methods" id="toc-using-standard-dataframe-methods" class="nav-link" data-scroll-target="#using-standard-dataframe-methods"><span class="header-section-number">5.10.1</span> Using standard DataFrame methods</a></li>
  <li><a href="#sec-agg-method" id="toc-sec-agg-method" class="nav-link" data-scroll-target="#sec-agg-method"><span class="header-section-number">5.10.2</span> Using the <code>agg()</code> method</a></li>
  <li><a href="#without-groups-we-calculate-a-aggregate-of-the-entire-dataframe" id="toc-without-groups-we-calculate-a-aggregate-of-the-entire-dataframe" class="nav-link" data-scroll-target="#without-groups-we-calculate-a-aggregate-of-the-entire-dataframe"><span class="header-section-number">5.10.3</span> Without groups, we calculate a aggregate of the entire DataFrame</a></li>
  <li><a href="#sec-group-by" id="toc-sec-group-by" class="nav-link" data-scroll-target="#sec-group-by"><span class="header-section-number">5.10.4</span> Calculating aggregates per group in your DataFrame</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-transforming-dataframes-part1" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transforming your Spark DataFrame - Part 1</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Virtually every data analysis or data pipeline will include some ETL (<em>Extract, Transform, Load</em>) process, and the T is an essential part of it. Because, you almost never have an input data, or a initial DataFrame that perfectly fits your needs.</p>
<p>This means that you always have to transform the initial data that you have, to a specific format that you can use in your analysis. In this chapter, you will learn how to apply some of these basic transformations to your Spark DataFrame.</p>
<section id="sec-df-defining-transformations" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-df-defining-transformations"><span class="header-section-number">5.1</span> Defining transformations</h2>
<p>Spark DataFrames are <strong>immutable</strong>, meaning that, they cannot be directly changed. But you can use an existing DataFrame to create a new one, based on a set of transformations. In other words, you define a new DataFrame as a transformed version of an older DataFrame.</p>
<p>Basically every <code>pyspark</code> program that you write will have such transformations. Spark support many types of transformations, however, in this chapter, we will focus on six basic transformations that you can apply to a DataFrame:</p>
<ul>
<li>Filtering rows based on a logical condition;</li>
<li>Selecting a subset of rows;</li>
<li>Selecting specific columns;</li>
<li>Adding or deleting columns;</li>
<li>Sorting rows;</li>
<li>Calculating aggregates;</li>
</ul>
<p>Therefore, when you apply one of the above transformations to an existing DataFrame, you will get a new DataFrame as a result. You usually combine multiple transformations together to get your desired result. As a first example, lets get back to the <code>df</code> DataFrame:</p>
<div id="c144b919" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> date</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> Row</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  Row(<span class="bu">id</span> <span class="op">=</span> <span class="dv">1</span>, value <span class="op">=</span> <span class="fl">28.3</span>, date <span class="op">=</span> date(<span class="dv">2021</span>,<span class="dv">1</span>,<span class="dv">1</span>)),</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  Row(<span class="bu">id</span> <span class="op">=</span> <span class="dv">2</span>, value <span class="op">=</span> <span class="fl">15.8</span>, date <span class="op">=</span> date(<span class="dv">2021</span>,<span class="dv">1</span>,<span class="dv">1</span>)),</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  Row(<span class="bu">id</span> <span class="op">=</span> <span class="dv">3</span>, value <span class="op">=</span> <span class="fl">20.1</span>, date <span class="op">=</span> date(<span class="dv">2021</span>,<span class="dv">1</span>,<span class="dv">2</span>)),</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  Row(<span class="bu">id</span> <span class="op">=</span> <span class="dv">4</span>, value <span class="op">=</span> <span class="fl">12.6</span>, date <span class="op">=</span> date(<span class="dv">2021</span>,<span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.createDataFrame(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the example below, to create a new DataFrame called <code>big_values</code>, we begin with the <code>df</code> DataFrame, then, we filter its rows where <code>value</code> is greater than 15, then, we select <code>date</code> and <code>value</code> columns, then, we sort the rows based on the <code>value</code> column. So, this set of sequential transformations (filter it, then, select it, then, order it, …) defines what this new <code>big_values</code> DataFrame is.</p>
<div id="8247dbd1" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> col</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># You define a chain of transformations to</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new DataFrame</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>big_values <span class="op">=</span> df<span class="op">\</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(col(<span class="st">'value'</span>) <span class="op">&gt;</span> <span class="dv">15</span>)<span class="op">\</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  .select(<span class="st">'date'</span>, <span class="st">'value'</span>)<span class="op">\</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  .orderBy(<span class="st">'value'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Thus, to apply a transformation to an existing DataFrame, we use DataFrame methods such as <code>select()</code>, <code>filter()</code>, <code>orderBy()</code> and many others. Remember, these are methods from the python class that defines Spark DataFrame’s (i.e.&nbsp;the <code>pyspark.sql.dataframe.DataFrame</code> class).</p>
<p>This means that you can apply these transformations only to Spark DataFrames, and no other kind of python object. For example, if you try to use the <code>orderBy()</code> method in a standard python string (i.e.&nbsp;an object of class <code>str</code>), you will get an <code>AttributeError</code> error. Because this class of object in python, does not have a <code>orderBy()</code> method:</p>
<div id="df277870" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="st">"A python string"</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>s.orderBy(<span class="st">'value'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
AttributeError: 'str' object has no attribute 'orderBy'</code></pre>
<p>Each one of these DataFrame methods create a <em>lazily evaluated transformation</em>. Once again, we see the <strong>lazy</strong> aspect of Spark doing its work here. All these transformation methods are lazily evaluated, meaning that, Spark will only check if they make sense with the initial DataFrame that you have. Spark will not actually perform these transformations on your initial DataFrame, not untill you trigger these transformations with an <strong>action</strong>.</p>
</section>
<section id="sec-dataframe-actions" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="sec-dataframe-actions"><span class="header-section-number">5.2</span> Triggering calculations with actions</h2>
<p>Therefore, Spark will avoid performing any heavy calculation until such calculation is really needed. But how or when Spark will face this decision? <strong>When it encounters an action</strong>. An action is the tool you have to trigger Spark to actually perform the transformations you have defined.</p>
<blockquote class="blockquote">
<p>An action instructs Spark to compute the result from a series of transformations. <span class="citation" data-cites="chambers2018">(<a href="references.html#ref-chambers2018" role="doc-biblioref">Chambers and Zaharia 2018</a>)</span>.</p>
</blockquote>
<p>There are four kinds of actions in Spark:</p>
<ul>
<li>Showing an output in the console;</li>
<li>Writing data to some file or data source;</li>
<li>Collecting data from a Spark DataFrame to native objects in python (or Java, Scala, R, etc.);</li>
<li>Counting the number of rows in a Spark DataFrame;</li>
</ul>
<p>You already know the first type of action, because we used it before with the <code>show()</code> method. This <code>show()</code> method is an action by itself, because you are asking Spark to show some output to you. So we can make Spark to actually calculate the transformations that defines the <code>big_values</code> DataFrame, by asking Spark to show this DataFrame to us.</p>
<div id="933919e7" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>big_values.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[Stage 0:&gt;                                                        (0 + 12) / 12]                                                                                </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>+----------+-----+
|      date|value|
+----------+-----+
|2021-01-01| 15.8|
|2021-01-02| 20.1|
|2021-01-01| 28.3|
+----------+-----+
</code></pre>
</div>
</div>
<p>Another very useful action is the <code>count()</code> method, that gives you the number of rows in a DataFrame. To be able to count the number of rows in a DataFrame, Spark needs to access this DataFrame in the first place. That is why this <code>count()</code> method behaves as an action. Spark will perform the transformations that defines <code>big_values</code> to access the actual rows of this DataFrame and count them.</p>
<div id="53284f1e" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>big_values.count()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>3</code></pre>
</div>
</div>
<p>Furthermore, sometimes, you want to collect the data of a Spark DataFrame to use it inside python. In other words, sometimes you need to do some work that Spark cannot do by itself. To do so, you collect part of the data that is being generated by Spark, and store it inside a normal python object to use it in a standard python program.</p>
<p>That is what the <code>collect()</code> method do. It transfers all the data of your Spark DataFrame into a standard python list that you can easily access with python. More specifically, you get a python list full of <code>Row()</code> values:</p>
<div id="cc4fbbbd" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> big_values.collect()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Row(date=datetime.date(2021, 1, 1), value=15.8), Row(date=datetime.date(2021, 1, 2), value=20.1), Row(date=datetime.date(2021, 1, 1), value=28.3)]</code></pre>
</div>
</div>
<p>The <code>take()</code> method is very similar to <code>collect()</code>. But you usually apply <code>take()</code> when you need to collect just a small section of your DataFrame (and not the entire thing), like the first <code>n</code> rows.</p>
<div id="9d89e79c" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>first_row <span class="op">=</span> big_values.take(n)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(first_row)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Row(date=datetime.date(2021, 1, 1), value=15.8)]</code></pre>
</div>
</div>
<p>The last action would be the <code>write</code> method of a Spark DataFrame, but we will explain this method latter at <a href="07-import.html" class="quarto-xref"><span>Chapter 6</span></a>.</p>
</section>
<section id="sec-narrow-wide" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="sec-narrow-wide"><span class="header-section-number">5.3</span> Understanding narrow and wide transformations</h2>
<p>There are two kinds of transformations in Spark: narrow and wide transformations. Remember, a Spark DataFrame is divided into many small parts (called partitions), and, these parts are spread across the cluster. The basic difference between narrow and wide transformations, is if the transformation forces Spark to read data from multiple partitions to generate a single part of the result of that transformation, or not.</p>
<p>More technically, narrow transformations are simply transformations where 1 input data (or 1 partition of the input DataFrame) contributes to only 1 partition of the output.</p>
<div id="fig-narrow-transformations" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-narrow-transformations-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../Figures/narrow-transformations.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-narrow-transformations-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.1: Presenting narrow transformations
</figcaption>
</figure>
</div>
<p>In other words, each partition of your input DataFrame will be used (<em>separately</em>) to generate one individual part of the result of your transformation. As another perspective, you can understand narrow transformations as those where Spark does not need to read the entire input DataFrame to generate a single and small piece of your result.</p>
<p>A classic example of narrow transformation is a filter. For example, suppose you have three students (Anne, Carls and Mike), and that each one has a bag full of blue, orange and red balls mixed. Now, suppose you asked them to collect all the red balls of these bags, and combined them in a single bag.</p>
<p>To do this task, Mike does not need to know what balls are inside of the bag of Carls or Anne. He just need to collect the red balls that are solely on his bag. At the end of the task, each student will have a part of the end result (that is, all the red balls that were in his own bag), and they just need to combine all these parts to get the total result.</p>
<p>The same thing applies to filters in Spark DataFrames. When you filter all the rows where the column <code>state</code> is equal to <code>"Alaska"</code>, Spark will filter all the rows in each partition separately, and then, will combine all the outputs to get the final result.</p>
<p>In contrast, wide transformations are the opposite of that. In wide transformations, Spark needs to use more than 1 partition of the input DataFrame to generate a small piece of the result.</p>
<div id="fig-wide-transformations" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-wide-transformations-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../Figures/wide-transformations.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-wide-transformations-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.2: Presenting wide transformations
</figcaption>
</figure>
</div>
<p>When this kind of transformation happens, each worker node of the cluster needs to share his partition with the others. In other words, what happens is a partition shuffle. Each worker node sends his partition to the others, so they can have access to it, while performing their assigned tasks.</p>
<p>Partition shuffles are a very popular topic in Apache Spark, because they can be a serious source of inefficiency in your Spark application <span class="citation" data-cites="chambers2018">(<a href="references.html#ref-chambers2018" role="doc-biblioref">Chambers and Zaharia 2018</a>)</span>. In more details, when these shuffles happens, Spark needs to write data back to the hard disk of the computer, and this is not a very fast operation. It does not mean that wide transformations are bad or slow, just that the shuffles they are producing can be a problem.</p>
<p>A classic example of wide operation is a grouped aggregation. For example, lets suppose we had a DataFrame with the daily sales of multiple stores spread across the country, and, we wanted to calculate the total sales per city/region. To calculate the total sales of a specific city, like “São Paulo”, Spark would need to find all the rows that corresponds to this city, before adding the values, and these rows can be spread across multiple partitions of the cluster.</p>
</section>
<section id="sec-transf-dataframe" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="sec-transf-dataframe"><span class="header-section-number">5.4</span> The <code>transf</code> DataFrame</h2>
<p>To demonstrate some of the next examples in this chapter, we will use a different DataFrame called <code>transf</code>. The data that represents this DataFrame is freely available as a CSV file. You can download this CSV at the repository of this book<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>With the code below, you can import the data from the <code>transf.csv</code> CSV file, to recreate the <code>transf</code> DataFrame in your Spark Session:</p>
<div id="0e9d9861" class="cell" data-cache="true" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.types <span class="im">import</span> StructType, StructField</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.types <span class="im">import</span> DoubleType, StringType</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.types <span class="im">import</span> LongType, TimestampType, DateType</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> <span class="st">"../Data/transf.csv"</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>schema <span class="op">=</span> StructType([</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  StructField(<span class="st">'dateTransfer'</span>, DateType(), <span class="va">False</span>),</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  StructField(<span class="st">'datetimeTransfer'</span>, TimestampType(), <span class="va">False</span>),</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  StructField(<span class="st">'clientNumber'</span>, LongType(), <span class="va">False</span>),</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  StructField(<span class="st">'transferValue'</span>, DoubleType(), <span class="va">False</span>),</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>  StructField(<span class="st">'transferCurrency'</span>, StringType(), <span class="va">False</span>),</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>  StructField(<span class="st">'transferID'</span>, LongType(), <span class="va">False</span>),</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>  StructField(<span class="st">'transferLog'</span>, StringType(), <span class="va">False</span>),</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>  StructField(<span class="st">'destinationBankNumber'</span>, LongType(), <span class="va">False</span>),</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>  StructField(<span class="st">'destinationBankBranch'</span>, LongType(), <span class="va">False</span>),</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>  StructField(<span class="st">'destinationBankAccount'</span>, StringType(), <span class="va">False</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>transf <span class="op">=</span> spark.read<span class="op">\</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>  .csv(path, schema <span class="op">=</span> schema, sep <span class="op">=</span> <span class="st">";"</span>, header <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You could also use the <code>pandas</code> library to read the DataFrame directly from GitHub, without having to manually download the file:</p>
<div id="6a361003" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">'https://raw.githubusercontent.com/'</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> url <span class="op">+</span> <span class="st">'pedropark99/Introd-pyspark/'</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> url <span class="op">+</span> <span class="st">'main/Data/transf.csv'</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>transf_pd <span class="op">=</span> pd.read_csv(</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  url, sep <span class="op">=</span> <span class="st">';'</span>,</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  dtype <span class="op">=</span> <span class="bu">str</span>,</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  keep_default_na <span class="op">=</span> <span class="va">False</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>transf_pd[<span class="st">'transferValue'</span>] <span class="op">=</span> (</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  transf_pd[<span class="st">'transferValue'</span>].astype(<span class="st">'float'</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>columns_to_int <span class="op">=</span> [</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>  <span class="st">'clientNumber'</span>,</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>  <span class="st">'transferID'</span>,</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>  <span class="st">'destinationBankNumber'</span>,</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>  <span class="st">'destinationBankBranch'</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> column <span class="kw">in</span> columns_to_int:</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>  transf_pd[column] <span class="op">=</span> transf_pd[column].astype(<span class="st">'int'</span>)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> col</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>transf <span class="op">=</span> spark.createDataFrame(transf_pd)<span class="op">\</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>  .withColumn(<span class="st">'dateTransfer'</span>, col(<span class="st">'dateTransfer'</span>).cast(<span class="st">'date'</span>))<span class="op">\</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>  .withColumn(</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">'datetimeTransfer'</span>,</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">'datetimeTransfer'</span>).cast(<span class="st">'timestamp'</span>)</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This <code>transf</code> DataFrame contains bank transfer records from a fictitious bank. Before I show you the actual data of this DataFrame, is useful to give you a quick description of each column that it contains:</p>
<ul>
<li><code>dateTransfer</code>: the date when the transfer occurred;</li>
<li><code>datetimeTransfer</code>: the date and time when the transfer occurred;</li>
<li><code>clientNumber</code> the unique number that identifies a client of the bank;</li>
<li><code>transferValue</code>: the nominal value that was transferred;</li>
<li><code>transferCurrency</code>: the currency of the nominal value transferred;</li>
<li><code>transferID</code>: an unique ID for the transfer;</li>
<li><code>transferLog</code>: store any error message that may have appeared during the execution of the transfer;</li>
<li><code>destinationBankNumber</code>: the transfer destination bank number;</li>
<li><code>destinationBankBranch</code>: the transfer destination branch number;</li>
<li><code>destinationBankAccount</code>: the transfer destination account number;</li>
</ul>
<p>Now, to see the actual data of this DataFrame, we can use the <code>show()</code> action as usual.</p>
<div id="e9e344f6" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>transf.show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
|  2022-12-31|2022-12-31 10:32:07|        4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|  2022-12-31|2022-12-31 02:53:44|        1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>As you can see below, this <code>transf</code> DataFrame have 2421 rows in total:</p>
<div id="d149e293" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>transf.count()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>2421</code></pre>
</div>
</div>
</section>
<section id="filtering-rows-of-your-dataframe" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="filtering-rows-of-your-dataframe"><span class="header-section-number">5.5</span> Filtering rows of your DataFrame</h2>
<p>To filter specific rows of a DataFrame, <code>pyspark</code> offers two equivalent DataFrame methods called <code>where()</code> and <code>filter()</code>. In other words, they both do the same thing, and work in the same way. These methods receives as input a logical expression that translates what you want to filter.</p>
<p>As a first example, lets suppose you wanted to inspect all the rows from the <code>transf</code> DataFrame where <code>transferValue</code> is less than 1000. To do so, you can use the following code:</p>
<div id="b4074580" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(<span class="st">"transferValue &lt; 1000"</span>)<span class="op">\</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-18|2022-12-18 08:45:30|        1297|       142.66|        dollar $|  20223467|       NULL|                  421|                 5420|               43088-1|
|  2022-12-13|2022-12-13 20:44:23|        5516|       992.15|        dollar $|  20223442|       NULL|                   33|                 5420|               41609-8|
|  2022-11-24|2022-11-24 20:01:39|        1945|       174.64|        dollar $|  20223319|       NULL|                  421|                 2400|               34025-8|
|  2022-11-07|2022-11-07 16:35:57|        4862|       570.69|        dollar $|  20223212|       NULL|                  290|                 5420|               51165-3|
|  2022-11-04|2022-11-04 20:00:34|        1297|        854.0|        dollar $|  20223194|       NULL|                  421|                 4078|               43478-6|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>Writing simple SQL logical expression inside a string is the most easy and “clean” way to create a filter expression in <code>pyspark</code>. However, you could also write the same exact expression in a more “pythonic” way, using the <code>col()</code> function from <code>pyspark.sql.functions</code> module.</p>
<div id="7c4eda7d" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> col</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(col(<span class="st">"transferValue"</span>) <span class="op">&lt;</span> <span class="dv">1000</span>)<span class="op">\</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-18|2022-12-18 08:45:30|        1297|       142.66|        dollar $|  20223467|       NULL|                  421|                 5420|               43088-1|
|  2022-12-13|2022-12-13 20:44:23|        5516|       992.15|        dollar $|  20223442|       NULL|                   33|                 5420|               41609-8|
|  2022-11-24|2022-11-24 20:01:39|        1945|       174.64|        dollar $|  20223319|       NULL|                  421|                 2400|               34025-8|
|  2022-11-07|2022-11-07 16:35:57|        4862|       570.69|        dollar $|  20223212|       NULL|                  290|                 5420|               51165-3|
|  2022-11-04|2022-11-04 20:00:34|        1297|        854.0|        dollar $|  20223194|       NULL|                  421|                 4078|               43478-6|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>You still have a more verbose alternative, that does not require the <code>col()</code> function. With this method, you refer to the specific column using the dot operator (<code>.</code>), like in the example below:</p>
<div id="7ee1fcfb" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This will give you the exact</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># same result of the examples above</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(transf.transferValue <span class="op">&lt;</span> <span class="dv">1000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="logical-operators-available" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="logical-operators-available"><span class="header-section-number">5.5.1</span> Logical operators available</h3>
<p>As we saw in the previous section, there are two ways to write logical expressions in <code>pyspark</code>: 1) write a SQL logical expression inside a string; 2) or, write a python logical expression using the <code>col()</code> function.</p>
<p>If you choose to write a SQL logical expressions in a string, you need to use the logical operators of SQL in your expression (not the logical operators of python). In the other hand, if you choose to write in the “python” way, then, you need to use the logical operators of python instead.</p>
<p>The logical operators of SQL are described in the table below:</p>
<div id="tbl-logical-operators-sql" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-logical-operators-sql-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5.1: List of logical operators of SQL
</figcaption>
<div aria-describedby="tbl-logical-operators-sql-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 24%">
<col style="width: 64%">
</colgroup>
<thead>
<tr class="header">
<th>Operator</th>
<th>Example of expression</th>
<th>Meaning of the expression</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt;</td>
<td><code>x &lt; y</code></td>
<td>is <code>x</code> less than <code>y</code>?</td>
</tr>
<tr class="even">
<td>&gt;</td>
<td><code>x &gt; y</code></td>
<td>is <code>x</code> greater than <code>y</code>?</td>
</tr>
<tr class="odd">
<td>&lt;=</td>
<td><code>x &lt;= y</code></td>
<td>is <code>x</code> less than or equal to <code>y</code>?</td>
</tr>
<tr class="even">
<td>&gt;=</td>
<td><code>x &gt;= y</code></td>
<td>is <code>x</code> greater than or equal to <code>y</code>?</td>
</tr>
<tr class="odd">
<td>==</td>
<td><code>x == y</code></td>
<td>is <code>x</code> equal to <code>y</code>?</td>
</tr>
<tr class="even">
<td>!=</td>
<td><code>x != y</code></td>
<td>is <code>x</code> not equal to <code>y</code>?</td>
</tr>
<tr class="odd">
<td>in</td>
<td><code>x in y</code></td>
<td>is <code>x</code> one of the values listed in <code>y</code>?</td>
</tr>
<tr class="even">
<td>and</td>
<td><code>x and y</code></td>
<td>both logical expressions <code>x</code> and <code>y</code> are true?</td>
</tr>
<tr class="odd">
<td>or</td>
<td><code>x or y</code></td>
<td>at least one of logical expressions <code>x</code> and <code>y</code> are true?</td>
</tr>
<tr class="even">
<td>not</td>
<td><code>not x</code></td>
<td>is the logical expression <code>x</code> not true?</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>And, the logical operators of python are described in the table below:</p>
<div id="tbl-logical-operators-python" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-logical-operators-python-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5.2: List of logical operators of python
</figcaption>
<div aria-describedby="tbl-logical-operators-python-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 24%">
<col style="width: 64%">
</colgroup>
<thead>
<tr class="header">
<th>Operator</th>
<th>Example of expression</th>
<th>Meaning of the expression</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt;</td>
<td><code>x &lt; y</code></td>
<td>is <code>x</code> less than <code>y</code>?</td>
</tr>
<tr class="even">
<td>&gt;</td>
<td><code>x &gt; y</code></td>
<td>is <code>x</code> greater than <code>y</code>?</td>
</tr>
<tr class="odd">
<td>&lt;=</td>
<td><code>x &lt;= y</code></td>
<td>is <code>x</code> less than or equal to <code>y</code>?</td>
</tr>
<tr class="even">
<td>&gt;=</td>
<td><code>x &gt;= y</code></td>
<td>is <code>x</code> greater than or equal to <code>y</code>?</td>
</tr>
<tr class="odd">
<td>==</td>
<td><code>x == y</code></td>
<td>is <code>x</code> equal to <code>y</code>?</td>
</tr>
<tr class="even">
<td>!=</td>
<td><code>x != y</code></td>
<td>is <code>x</code> not equal to <code>y</code>?</td>
</tr>
<tr class="odd">
<td>&amp;</td>
<td><code>x &amp; y</code></td>
<td>both logical expressions <code>x</code> and <code>y</code> are true?</td>
</tr>
<tr class="even">
<td>|</td>
<td><code>x | y</code></td>
<td>at least one of logical expressions <code>x</code> and <code>y</code> are true?</td>
</tr>
<tr class="odd">
<td>~</td>
<td><code>~x</code></td>
<td>is the logical expression <code>x</code> not true?</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="connecting-multiple-logical-expressions" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="connecting-multiple-logical-expressions"><span class="header-section-number">5.5.2</span> Connecting multiple logical expressions</h3>
<p>Sometimes, you need to write more complex logical expressions to correctly describe the rows you are interested in. That is, when you combine multiple logical expressions together.</p>
<p>As an example, lets suppose you wanted all the rows in <code>transf</code> DataFrame from client of number 1297 where the transfer value is smaller than 1000, and the date of the transfer is after 20 of February 2022. These conditions are dependent, that is, they are connected to each other (the client number, the transfer value and the date of the transfer). That is why I used the <code>and</code> keyword between each condition in the example below (i.e.&nbsp;to connect these three conditions together).</p>
<div id="ee04a545" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>condition <span class="op">=</span> <span class="st">'''</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="st">  transferValue &lt; 1000</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="st">  and clientNumber == 1297 </span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="st">  and dateTransfer &gt; '2022-02-20'</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(condition)<span class="op">\</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>  .show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-18|2022-12-18 08:45:30|        1297|       142.66|        dollar $|  20223467|       NULL|                  421|                 5420|               43088-1|
|  2022-11-04|2022-11-04 20:00:34|        1297|        854.0|        dollar $|  20223194|       NULL|                  421|                 4078|               43478-6|
|  2022-02-27|2022-02-27 13:27:44|        1297|       697.21|        dollar $|  20221505|       NULL|                  421|                 1100|               60414-7|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
</code></pre>
</div>
</div>
<p>I could translate this logical expression into the “pythonic” way (using the <code>col()</code> function). However, I would have to surround each individual expression by parentheses, and, use the <code>&amp;</code> operator to substitute the <code>and</code> keyword.</p>
<div id="438491c3" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">'transferValue'</span>) <span class="op">&lt;</span> <span class="dv">1000</span>) <span class="op">&amp;</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">'clientNumber'</span>) <span class="op">==</span> <span class="dv">1297</span>) <span class="op">&amp;</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">'dateTransfer'</span>) <span class="op">&gt;</span> <span class="st">'2022-02-20'</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  )<span class="op">\</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  .show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-18|2022-12-18 08:45:30|        1297|       142.66|        dollar $|  20223467|       NULL|                  421|                 5420|               43088-1|
|  2022-11-04|2022-11-04 20:00:34|        1297|        854.0|        dollar $|  20223194|       NULL|                  421|                 4078|               43478-6|
|  2022-02-27|2022-02-27 13:27:44|        1297|       697.21|        dollar $|  20221505|       NULL|                  421|                 1100|               60414-7|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
</code></pre>
</div>
</div>
<p>This a <strong>very important detail</strong>, because it is very easy to forget. When building your complex logical expressions in the “python” way, always <strong>remember to surround each expression by a pair of parentheses</strong>. Otherwise, you will get a very confusing and useless error message, like this:</p>
<div id="0c5b9ff2" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">'transferValue'</span>) <span class="op">&lt;</span> <span class="dv">1000</span> <span class="op">&amp;</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">'clientNumber'</span>) <span class="op">==</span> <span class="dv">1297</span> <span class="op">&amp;</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">'dateTransfer'</span>) <span class="op">&gt;</span> <span class="st">'2022-02-20'</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>  )<span class="op">\</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Py4JError: An error occurred while calling o216.and. Trace:
py4j.Py4JException: Method and([class java.lang.Integer]) does not exist
    at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)
    at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)
    at py4j.Gateway.invoke(Gateway.java:274)
    at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    at py4j.commands.CallCommand.execute(CallCommand.java:79)
    at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
    at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
    at java.base/java.lang.Thread.run(Thread.java:829)</code></pre>
<p>In the above examples, we have logical expressions that are dependent on each other. But, lets suppose these conditions were independent. In this case, we would use the <code>or</code> keyword, instead of <code>and</code>. Now, Spark will look for every row of <code>transf</code> where <code>transferValue</code> is smaller than 1000, or, <code>clientNumber</code> is equal to 1297, or, <code>dateTransfer</code> is greater than 20 of February 2022.</p>
<div id="cfeaa1f8" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>condition <span class="op">=</span> <span class="st">'''</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="st">  transferValue &lt; 1000</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="st">  or clientNumber == 1297 </span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="st">  or dateTransfer &gt; '2022-02-20'</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(condition)<span class="op">\</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
|  2022-12-31|2022-12-31 10:32:07|        4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|  2022-12-31|2022-12-31 02:53:44|        1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>To translate this expression into the pythonic way, we have to substitute the <code>or</code> keyword by the <code>|</code> operator, and surround each expression by parentheses again:</p>
<div id="8ce5d215" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">'transferValue'</span>) <span class="op">&lt;</span> <span class="dv">1000</span>) <span class="op">|</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">'clientNumber'</span>) <span class="op">==</span> <span class="dv">1297</span>) <span class="op">|</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">'dateTransfer'</span>) <span class="op">&gt;</span> <span class="st">'2022-02-20'</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  )<span class="op">\</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
|  2022-12-31|2022-12-31 10:32:07|        4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|  2022-12-31|2022-12-31 02:53:44|        1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>You can also increase the complexity of your logical expressions by mixing dependent expressions with independent expressions. For example, to filter all the rows where <code>dateTransfer</code> is greater than or equal to 01 of October 2022, and <code>clientNumber</code> is either 2727 or 5188, you would have the following code:</p>
<div id="9619b8d7" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>condition <span class="op">=</span> <span class="st">'''</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="st">  (clientNumber == 2727 or clientNumber == 5188)</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="st">  and dateTransfer &gt;= '2022-10-01'</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(condition)<span class="op">\</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-29|2022-12-29 10:22:02|        2727|      4666.25|          euro €|  20223541|       NULL|                   33|                 5420|               83070-8|
|  2022-12-27|2022-12-27 03:58:25|        5188|      7821.69|        dollar $|  20223522|       NULL|                   33|                 4078|               46571-3|
|  2022-12-26|2022-12-25 23:45:02|        2727|      3261.73| british pound £|  20223515|       NULL|                  421|                 6317|               66040-9|
|  2022-12-23|2022-12-23 05:32:49|        2727|       8042.0|        dollar $|  20223496|       NULL|                  290|                 5420|               37759-7|
|  2022-12-22|2022-12-22 06:02:47|        5188|      8175.67|        dollar $|  20223490|       NULL|                  666|                 8800|               42657-8|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>If you investigate the above condition carefully, maybe, you will identify that this condition could be rewritten in a simpler format, by using the <code>in</code> keyword. This way, Spark will look for all the rows where <code>clientNumber</code> is equal to one of the listed values (2727 or 5188), and, that <code>dateTransfer</code> is greater than or equal to 01 of October 2022.</p>
<div id="17567c43" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>condition <span class="op">=</span> <span class="st">'''</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="st">  clientNumber in (2727, 5188)</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="st">  and dateTransfer &gt;= '2022-10-01'</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(condition)<span class="op">\</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-29|2022-12-29 10:22:02|        2727|      4666.25|          euro €|  20223541|       NULL|                   33|                 5420|               83070-8|
|  2022-12-27|2022-12-27 03:58:25|        5188|      7821.69|        dollar $|  20223522|       NULL|                   33|                 4078|               46571-3|
|  2022-12-26|2022-12-25 23:45:02|        2727|      3261.73| british pound £|  20223515|       NULL|                  421|                 6317|               66040-9|
|  2022-12-23|2022-12-23 05:32:49|        2727|       8042.0|        dollar $|  20223496|       NULL|                  290|                 5420|               37759-7|
|  2022-12-22|2022-12-22 06:02:47|        5188|      8175.67|        dollar $|  20223490|       NULL|                  666|                 8800|               42657-8|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
</section>
<section id="translating-the-in-keyword-to-the-pythonic-way" class="level3" data-number="5.5.3">
<h3 data-number="5.5.3" class="anchored" data-anchor-id="translating-the-in-keyword-to-the-pythonic-way"><span class="header-section-number">5.5.3</span> Translating the <code>in</code> keyword to the pythonic way</h3>
<p>Python does have a <code>in</code> keyword just like SQL, but, this keyword does not work as expected in <code>pyspark</code>. To write a logical expression, using the pythonic way, that filters the rows where a column is equal to one of the listed values, you can use the <code>isin()</code> method.</p>
<p>This method belongs to the <code>Column</code> class, so, you should always use <code>isin()</code> after a column name or a <code>col()</code> function. In the example below, we are filtering the rows where <code>destinationBankNumber</code> is 290 or 666:</p>
<div id="4d58793a" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">filter</span>(col(<span class="st">'destinationBankNumber'</span>).isin(<span class="dv">290</span>, <span class="dv">666</span>))<span class="op">\</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|  2022-12-31|2022-12-31 02:44:46|        1121|       7158.0|          zing ƒ|  20223558|       NULL|                  290|                 1100|               35424-4|
|  2022-12-31|2022-12-31 01:02:06|        4862|       6714.0|        dollar $|  20223557|       NULL|                  666|                 1002|               71839-1|
|  2022-12-31|2022-12-31 00:48:47|        3294|     10882.52|        dollar $|  20223556|       NULL|                  666|                 2231|               50190-5|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
</section>
<section id="negating-logical-conditions" class="level3" data-number="5.5.4">
<h3 data-number="5.5.4" class="anchored" data-anchor-id="negating-logical-conditions"><span class="header-section-number">5.5.4</span> Negating logical conditions</h3>
<!-- Describe the ~ operator -->
<p>In some cases, is easier to describe what rows you <strong>do not want</strong> in your filter. That is, you want to negate (or invert) your logical expression. For this, SQL provides the <code>not</code> keyword, that you place before the logical expression you want to negate.</p>
<p>For example, we can filter all the rows of <code>transf</code> where <code>clientNumber</code> is not equal to 3284. Remember, the methods <code>filter()</code> and <code>where()</code> are equivalents or synonymous (they both mean the same thing).</p>
<div id="770679b9" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>condition <span class="op">=</span> <span class="st">'''</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="st">  not clientNumber == 3284</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  .where(condition)<span class="op">\</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
|  2022-12-31|2022-12-31 10:32:07|        4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|  2022-12-31|2022-12-31 02:53:44|        1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>To translate this expression to the pythonic way, we use the <code>~</code> operator. However, because we are negating the logical expression as a whole, is important to surround the entire expression with parentheses.</p>
<div id="2fefaa75" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  .where(<span class="op">~</span>(col(<span class="st">'clientNumber'</span>) <span class="op">==</span> <span class="dv">3284</span>))<span class="op">\</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
|  2022-12-31|2022-12-31 10:32:07|        4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|  2022-12-31|2022-12-31 02:53:44|        1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>If you forget to add the parentheses, Spark will think you are negating just the column, and not the entire expression. That would not make sense, and, as a result, Spark would throw an error:</p>
<div id="918b4bcc" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>  .where(<span class="op">~</span>col(<span class="st">'clientNumber'</span>) <span class="op">==</span> <span class="dv">3284</span>)<span class="op">\</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>AnalysisException: cannot resolve '(NOT clientNumber)' due to data type mismatch: argument 1 requires boolean type, however, 'clientNumber' is of bigint type.;
'Filter (NOT clientNumber#210L = 3284)</code></pre>
<p>Because the <code>~</code> operator is a little discrete and can go unnoticed, I sometimes use a different approach to negate my logical expressions. I make the entire expression equal to <code>False</code>. This way, I get all the rows where that particular expression is <code>False</code>. This makes my intention more visible in the code, but, is harder to write it.</p>
<div id="068afe4f" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter all the rows where `clientNumber` is not equal to</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2727 or 5188.</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>  .where( (col(<span class="st">'clientNumber'</span>).isin(<span class="dv">2727</span>, <span class="dv">5188</span>)) <span class="op">==</span> <span class="va">False</span> )<span class="op">\</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
|  2022-12-31|2022-12-31 10:32:07|        4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|  2022-12-31|2022-12-31 02:53:44|        1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
</section>
<section id="sec-filter-null-values" class="level3" data-number="5.5.5">
<h3 data-number="5.5.5" class="anchored" data-anchor-id="sec-filter-null-values"><span class="header-section-number">5.5.5</span> Filtering <code>null</code> values (i.e.&nbsp;missing data)</h3>
<p>Sometimes, the <code>null</code> values play an important role in your filter. You either want to collect all these <code>null</code> values, so you can investigate why they are null in the first place, or, you want to completely eliminate them from your DataFrame.</p>
<p>Because this is a special kind of value in Spark, with a special meaning (the “absence” of a value), you need to use a special syntax to correctly filter these values in your DataFrame. In SQL, you can use the <code>is</code> keyword to filter these values:</p>
<div id="cdeacc42" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>  .where(<span class="st">'transferLog is null'</span>)<span class="op">\</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
|  2022-12-31|2022-12-31 10:32:07|        4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|  2022-12-31|2022-12-31 02:53:44|        1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>However, if you want to remove these values from your DataFrame, then, you can just negate (or invert) the above expression with the <code>not</code> keyword, like this:</p>
<div id="df748d06" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>  .where(<span class="st">'not transferLog is null'</span>)<span class="op">\</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+--------------------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|         transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+--------------------+---------------------+---------------------+----------------------+
|  2022-12-05|2022-12-05 00:51:00|        2197|      8240.62|          zing ƒ|  20223383| 408 Request Timeout|                  666|                 1100|               58503-9|
|  2022-09-20|2022-09-19 21:59:51|        5188|       7583.9|        dollar $|  20222912|500 Server Unavai...|                  290|                 1979|               85242-1|
|  2022-09-03|2022-09-03 06:07:59|        3795|       3654.0|          zing ƒ|  20222814| 408 Request Timeout|                  290|                 9921|               60494-5|
|  2022-07-02|2022-07-02 15:29:50|        4465|       5294.0|        dollar $|  20222408|500 Server Unavai...|                  421|                 2400|               39070-3|
|  2022-06-14|2022-06-14 10:21:55|        1121|       7302.0|        dollar $|  20222273| 408 Request Timeout|                  666|                 5420|               47709-2|
+------------+-------------------+------------+-------------+----------------+----------+--------------------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>The <code>is</code> and <code>not</code> keywords in SQL have a special relation. Because you can create the same negation/inversion of the expression by inserting the <code>not</code> keyword in the middle of the expression (you can do this too in expressions with the <code>in</code> keyword). In other words, you might see, in someone else’s code, the same expression above written in this form:</p>
<div id="96381a8b" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>  .where(<span class="st">'transferLog is not null'</span>)<span class="op">\</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Both forms are equivalent and valid SQL logical expressions. But the latter is a strange version. Because we cannot use the <code>not</code> keyword in this manner on other kinds of logical expressions. Normally, we put the <code>not</code> keyword <strong>before</strong> the logical expression we want to negate, not in the middle of it. Anyway, just have in mind that this form of logical expression exists, and, that is a perfectly valid one.</p>
<p>When we translate the above examples to the “pythonic” way, many people tend to use the <code>null</code> equivalent of python, that is, the <code>None</code> value, in the expression. But as you can see in the result below, this method does not work as expected:</p>
<div id="98fa545f" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>  .where(col(<span class="st">'transferLog'</span>) <span class="op">==</span> <span class="va">None</span>)<span class="op">\</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+----------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+----------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
+------------+----------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
</code></pre>
</div>
</div>
<p>The correct way to do this in <code>pyspark</code>, is to use the <code>isNull()</code> method from the <code>Column</code> class.</p>
<div id="9ef4c5f3" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>  .where(col(<span class="st">'transferLog'</span>).isNull())<span class="op">\</span></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
|  2022-12-31|2022-12-31 10:32:07|        4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|  2022-12-31|2022-12-31 02:53:44|        1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>If you want to eliminate the <code>null</code> values, just use the inverse method <code>isNotNull()</code>.</p>
<div id="7e9315bd" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>  .where(col(<span class="st">'transferLog'</span>).isNotNull())<span class="op">\</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+--------------------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|         transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+--------------------+---------------------+---------------------+----------------------+
|  2022-12-05|2022-12-05 00:51:00|        2197|      8240.62|          zing ƒ|  20223383| 408 Request Timeout|                  666|                 1100|               58503-9|
|  2022-09-20|2022-09-19 21:59:51|        5188|       7583.9|        dollar $|  20222912|500 Server Unavai...|                  290|                 1979|               85242-1|
|  2022-09-03|2022-09-03 06:07:59|        3795|       3654.0|          zing ƒ|  20222814| 408 Request Timeout|                  290|                 9921|               60494-5|
|  2022-07-02|2022-07-02 15:29:50|        4465|       5294.0|        dollar $|  20222408|500 Server Unavai...|                  421|                 2400|               39070-3|
|  2022-06-14|2022-06-14 10:21:55|        1121|       7302.0|        dollar $|  20222273| 408 Request Timeout|                  666|                 5420|               47709-2|
+------------+-------------------+------------+-------------+----------------+----------+--------------------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
</section>
<section id="filtering-dates-and-datetimes-in-your-dataframe" class="level3" data-number="5.5.6">
<h3 data-number="5.5.6" class="anchored" data-anchor-id="filtering-dates-and-datetimes-in-your-dataframe"><span class="header-section-number">5.5.6</span> Filtering dates and datetimes in your DataFrame</h3>
<p>Just as a quick side note, when you want to filter rows of your DataFrame that fits into a particular date, you can easily write this particular date as a single string, like in the example below:</p>
<div id="d8ffa744" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>df_0702 <span class="op">=</span> transf<span class="op">\</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>  .where(col(<span class="st">'dateTransfer'</span>) <span class="op">==</span> <span class="st">'2022-07-02'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>When filtering datetimes you can also write the datetimes as strings, like this:</p>
<div id="8083977a" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>later_0330_pm <span class="op">=</span> transf.where(</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">'datetimeTransfer'</span>) <span class="op">&gt;</span> <span class="st">'2022-07-02 03:30:00'</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>However, is a better practice to write these particular values using the built-in <code>date</code> and <code>datetime</code> classes of python, like this:</p>
<div id="dc4dd55e" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> date, datetime</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> date(<span class="dv">2022</span>,<span class="dv">2</span>,<span class="dv">7</span>)</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>dt <span class="op">=</span> datetime(<span class="dv">2022</span>,<span class="dv">2</span>,<span class="dv">7</span>,<span class="dv">3</span>,<span class="dv">30</span>,<span class="dv">0</span>)</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter all rows where `dateTransfer`</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a><span class="co"># is equal to "2022-07-02"</span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>df_0702 <span class="op">=</span> transf.where(</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">'dateTransfer'</span>) <span class="op">==</span> d</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter all rows where `datetimeTransfer`</span></span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a><span class="co"># is greater than "2022-07-02 03:30:00"</span></span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a>later_0330_pm <span class="op">=</span> transf.where(</span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">'datetimeTransfer'</span>) <span class="op">&gt;</span> dt</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>When you translate the above expressions to SQL, you can also write the date and datetime values as strings. However, is also a good idea to use the <code>CAST()</code> SQL function to convert these string values into the correct data type before the actual filter. like this:</p>
<div id="58d8370b" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>condition_d <span class="op">=</span> <span class="st">'''</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="st">dateTransfer == CAST("2022-07-02" AS DATE)</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>condition_dt <span class="op">=</span> <span class="st">'''</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a><span class="st">dateTransfer &gt; CAST("2022-07-02 03:30:00" AS TIMESTAMP)</span></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter all rows where `dateTransfer`</span></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a><span class="co"># is equal to "2022-07-02"</span></span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>df_0702 <span class="op">=</span> transf.where(condition_d)</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter all rows where `datetimeTransfer`</span></span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a><span class="co"># is greater than "2022-07-02 03:30:00"</span></span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>later_0330_pm <span class="op">=</span> transf.where(condition_dt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In other words, with the SQL expression <code>CAST("2022-07-02 03:30:00" AS TIMESTAMP)</code> we are telling Spark to convert the literal string <code>"2022-07-02 03:30:00"</code> into an actual timestamp value.</p>
</section>
<section id="sec-filter-pattern-search" class="level3" data-number="5.5.7">
<h3 data-number="5.5.7" class="anchored" data-anchor-id="sec-filter-pattern-search"><span class="header-section-number">5.5.7</span> Searching for a particular pattern in string values</h3>
<p>Spark offers different methods to search a particular pattern within a string value. In this section, I want to describe how you can use these different methods to find specific rows in your DataFrame, that fit into the description of these patterns.</p>
<section id="starts-with-ends-with-and-contains" class="level4" data-number="5.5.7.1">
<h4 data-number="5.5.7.1" class="anchored" data-anchor-id="starts-with-ends-with-and-contains"><span class="header-section-number">5.5.7.1</span> Starts with, ends with and contains</h4>
<p>You can use the column methods <code>startswith()</code>, <code>endswith()</code> and <code>contains()</code>, to search for rows where a input string value starts with, ends with, or, contains a particular pattern, respectively.</p>
<p>These three methods returns a boolean value that indicates if the input string value matched the input pattern that you gave to the method. And you can use these boolean values they return to filter the rows of your DataFrame that fit into the description of these patterns.</p>
<p>Just as an example, in the following code, we are creating a new DataFrame called <code>persons</code>, that contains the description of 3 persons (Alice, Bob and Charlie). And I use these three methods to search for different rows in the DataFrame:</p>
<div id="74630134" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> col</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>persons <span class="op">=</span> spark.createDataFrame(</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>  [</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Alice'</span>, <span class="dv">25</span>),</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Bob'</span>, <span class="dv">30</span>),</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'Charlie'</span>, <span class="dv">35</span>)</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>  ],</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>  [<span class="st">'name'</span>, <span class="st">'age'</span>]</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter the DataFrame to include only rows</span></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a><span class="co"># where the "name" column starts with "A"</span></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>persons.<span class="bu">filter</span>(col(<span class="st">'name'</span>).startswith(<span class="st">'A'</span>))<span class="op">\</span></span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>  .show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-----+---+
| name|age|
+-----+---+
|Alice| 25|
+-----+---+
</code></pre>
</div>
</div>
<div id="1c006d47" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter the DataFrame to include only rows</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="co"># where the "name" column ends with "e"</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>persons.<span class="bu">filter</span>(col(<span class="st">'name'</span>).endswith(<span class="st">'e'</span>))<span class="op">\</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>  .show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------+---+
|   name|age|
+-------+---+
|  Alice| 25|
|Charlie| 35|
+-------+---+
</code></pre>
</div>
</div>
<div id="d099d0f0" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter the DataFrame to include only rows</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="co"># where the "name" column contains "ob"</span></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>persons.<span class="bu">filter</span>(col(<span class="st">'name'</span>).contains(<span class="st">'ob'</span>))<span class="op">\</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>  .show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+----+---+
|name|age|
+----+---+
| Bob| 30|
+----+---+
</code></pre>
</div>
</div>
</section>
<section id="sec-filter-regex-pattern" class="level4" data-number="5.5.7.2">
<h4 data-number="5.5.7.2" class="anchored" data-anchor-id="sec-filter-regex-pattern"><span class="header-section-number">5.5.7.2</span> Using regular expressions or SQL LIKE patterns</h4>
<p>In Spark, you can also use a particular “SQL LIKE pattern” or a regular pattern (a.k.a. regex) to filter the rows of a DataFrame, by using the <code>Column</code> methods <code>like()</code> and <code>rlike()</code>.</p>
<p>In essence, the <code>like()</code> method is the <code>pyspark</code> equivalent of the <code>LIKE</code> SQL operator. As a result, this <code>like()</code> method expects a SQL pattern as input. This means that you can use the SQL metacharacters <code>%</code> (to match any number of characters) and <code>_</code> (to match exactly one character) inside this pattern.</p>
<div id="ddf182a3" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>  .where(col(<span class="st">'transferCurrency'</span>).like(<span class="st">'british%'</span>))<span class="op">\</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-30|2022-12-30 11:30:23|        1455|       5141.0| british pound £|  20223552|       NULL|                  421|                 6552|               62671-3|
|  2022-12-30|2022-12-30 02:35:23|        5986|       6076.0| british pound £|  20223550|       NULL|                   33|                 4078|               83994-4|
|  2022-12-29|2022-12-29 15:24:04|        4862|       5952.0| british pound £|  20223544|       NULL|                  666|                 1002|               37736-6|
|  2022-12-29|2022-12-29 14:16:46|        2197|       8771.0| british pound £|  20223543|       NULL|                   33|                 1200|               32390-2|
|  2022-12-29|2022-12-29 06:51:24|        5987|       2345.0| british pound £|  20223539|       NULL|                   33|                 2231|               70909-9|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>Although the style of pattern matching used by <code>like()</code> being very powerful, you might need to use more powerful and flexible patterns. In those cases, you can use the <code>rlike()</code> method, which accepts a regular expression as input. In the example below, I am filtering rows where <code>destinationBankAccount</code> starts by the characters <code>54</code>.</p>
<div id="1c0bf4c6" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>regex <span class="op">=</span> <span class="st">'^54([0-9]</span><span class="sc">{3}</span><span class="st">)-[0-9]$'</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>  .where(col(<span class="st">'destinationBankAccount'</span>).rlike(regex))<span class="op">\</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-29|2022-12-29 02:54:23|        2197|       5752.0| british pound £|  20223536|       NULL|                  666|                 8800|               54159-1|
|  2022-12-27|2022-12-27 04:51:45|        4862|      11379.0|        dollar $|  20223523|       NULL|                   33|                 4425|               54796-3|
|  2022-12-05|2022-12-05 05:50:27|        4965|       5986.0| british pound £|  20223386|       NULL|                  421|                 1200|               54118-1|
|  2022-12-04|2022-12-04 14:31:42|        4965|       8123.0|        dollar $|  20223380|       NULL|                  666|                 3321|               54912-2|
|  2022-11-29|2022-11-29 16:23:07|        4862|       8060.0|          zing ƒ|  20223351|       NULL|                  421|                 8800|               54194-8|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="selecting-a-subset-of-rows-from-your-dataframe" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="selecting-a-subset-of-rows-from-your-dataframe"><span class="header-section-number">5.6</span> Selecting a subset of rows from your DataFrame</h2>
<p>At some point, you might need to use just a small piece of your DataFrame over the next steps of your pipeline, and not the entire thing. For example, you may want to select just the fisrt (or last) 5 rows of this DataFrame, or, maybe, you need to take a random sample of rows from it.</p>
<p>In this section I will discuss the main methods offered by Spark to deal with these scenarios. Each method returns a subset of rows from the original DataFrame as a result. But each method works differently from the other, and uses a different strategy to retrieve this subset.</p>
<section id="limiting-the-number-of-rows-in-your-dataframe" class="level3" data-number="5.6.1">
<h3 data-number="5.6.1" class="anchored" data-anchor-id="limiting-the-number-of-rows-in-your-dataframe"><span class="header-section-number">5.6.1</span> Limiting the number of rows in your DataFrame</h3>
<p>The <code>limit()</code> method is very similar to the <code>LIMIT</code> SQL keyword. It limits the number of rows present in your DataFrame to a specific amount. So, if I run <code>transf.limit(1)</code> I get a new DataFrame as a result, which have only a single row from the <code>transf</code> DataFrame. As you can see below:</p>
<div id="10ff83e3" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>single_transfer <span class="op">=</span> transf.limit(<span class="dv">1</span>)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>single_transfer.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
</code></pre>
</div>
</div>
<p>Is worth mentioning that the <code>limit()</code> method will always try to limit your original DataFrame, to the first <span class="math inline">\(n\)</span> rows. This means that the command <code>df.limit(430)</code> tries to limit the <code>df</code> DataFrame to its first 430 rows.</p>
<p>This also means that 430 is the maximum number of rows that will be taken from the <code>df</code> DataFrame. So, if <code>df</code> DataFrame has less than 430 lines, like 14 rows, than, nothing will happen, i.e.&nbsp;the result of <code>df.limit(430)</code> will be equivalent to the <code>df</code> DataFrame itself.</p>
</section>
<section id="getting-the-firstlast-n-rows-of-your-dataframe" class="level3" data-number="5.6.2">
<h3 data-number="5.6.2" class="anchored" data-anchor-id="getting-the-firstlast-n-rows-of-your-dataframe"><span class="header-section-number">5.6.2</span> Getting the first/last <span class="math inline">\(n\)</span> rows of your DataFrame</h3>
<p>The methods <code>head()</code> and <code>tail()</code> allows you to collect the first/last <span class="math inline">\(n\)</span> rows of your DataFrame, respectively. One key aspect from these methods, is that they return a list of <code>Row</code> values, instead of a new DataFrame (such as the <code>limit()</code> method). You can compare these methods to the <code>take()</code> and <code>collect()</code> methods that we introduced at <a href="#sec-dataframe-actions" class="quarto-xref"><span>Section 5.2</span></a>, because they both produce a list of <code>Row</code> values as well.</p>
<p>Now, the <code>head()</code> method produce the same output as the <code>take()</code> method. However, these two methods work very differently under the hoods, and, are recommended to be used in different scenarios.</p>
<p>More specifically, if you have a big DataFrame (i.e.&nbsp;a DataFrame with many rows) is recommended to use <code>take()</code> (instead of <code>head()</code>) to collect the first <span class="math inline">\(n\)</span> rows from it. Because the <code>head()</code> method makes Spark to load the entire DataFrame into the driver’s memory, and this can easily cause an “out of memory” situation for big DataFrames. So, use the <code>head()</code> method only for small DataFrames.</p>
<p>In the example below, we are using these methods to get the first and last 2 rows of the <code>transf</code> DataFrame:</p>
<div id="065193ca" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First 2 rows of `transf` DataFrame:</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>first2 <span class="op">=</span> transf.head(<span class="dv">2</span>)</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Last 2 rows of `transf` DataFrame:</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>last2 <span class="op">=</span> transf.tail(<span class="dv">2</span>)</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(last2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Row(dateTransfer=datetime.date(2022, 1, 1), datetimeTransfer=datetime.datetime(2022, 1, 1, 4, 7, 44), clientNumber=5987, transferValue=8640.06, transferCurrency='dollar $', transferID=20221144, transferLog=None, destinationBankNumber=666, destinationBankBranch=6552, destinationBankAccount='70021-4'), Row(dateTransfer=datetime.date(2022, 1, 1), datetimeTransfer=datetime.datetime(2022, 1, 1, 3, 56, 58), clientNumber=6032, transferValue=5076.61, transferCurrency='dollar $', transferID=20221143, transferLog=None, destinationBankNumber=33, destinationBankBranch=8800, destinationBankAccount='41326-5')]</code></pre>
</div>
</div>
</section>
<section id="taking-a-random-sample-of-your-dataframe" class="level3" data-number="5.6.3">
<h3 data-number="5.6.3" class="anchored" data-anchor-id="taking-a-random-sample-of-your-dataframe"><span class="header-section-number">5.6.3</span> Taking a random sample of your DataFrame</h3>
<p>With the <code>sample()</code> you can take a random sample of rows from your DataFrame. In other words, this method returns a new DataFrame with a random subset of rows from the original DataFrame.</p>
<p>This method have three main arguments, which are:</p>
<ul>
<li><code>withReplacement</code>: a boolean value indicating if the samples are with replacement or not. Defaults to <code>False</code>;</li>
<li><code>fraction</code>: the fraction of rows you want to sample from the DataFrame. Have to be a positive float value, from 0 to 1;</li>
<li><code>seed</code>: an integer representing the seed for the sampling process. This is an optional argument;</li>
</ul>
<p>In the example below, we are trying to get a sample that represents 15% of the original <code>transf</code> DataFrame, and using the integer 24 as our sampling seed:</p>
<div id="549b9dd5" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>transf_sample <span class="op">=</span> transf.sample(fraction <span class="op">=</span> <span class="fl">0.15</span>, seed <span class="op">=</span> <span class="dv">24</span>)</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>transf_sample.show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 01:02:06|        4862|       6714.0|        dollar $|  20223557|       NULL|                  666|                 1002|               71839-1|
|  2022-12-30|2022-12-30 00:18:25|        5832|       6333.0|        dollar $|  20223548|       NULL|                  666|                 8800|               78901-8|
|  2022-12-29|2022-12-29 06:51:24|        5987|       2345.0| british pound £|  20223539|       NULL|                   33|                 2231|               70909-9|
|  2022-12-27|2022-12-27 14:08:01|        3294|      6617.17|        dollar $|  20223526|       NULL|                  666|                 2231|               49767-2|
|  2022-12-26|2022-12-26 11:25:09|        5832|       8178.0|          euro €|  20223517|       NULL|                  290|                 8521|               39648-9|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>In other words, the <code>fraction</code> argument represents a fraction of the total number of rows in the original DataFrame. Since the <code>transf</code> DataFrame have 2421 rows in total, by setting the <code>fraction</code> argument to 0.15, we are asking Spark to collect a sample from <code>transf</code> that have approximately <span class="math inline">\(0.15 \times 2421 \approx 363\)</span> rows.</p>
<p>If we calculate the number of rows in <code>transf_sample</code> DataFrame, we can see that this DataFrame have a number of rows close to 363:</p>
<div id="669adb8b" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>transf_sample.count()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>355</code></pre>
</div>
</div>
<p>Furthermore, the sampling seed is just a way to ask Spark to produce the same random sample of the original DataFrame. That is, the sampling seed makes the result sample fixed. You always get the same random sample when you run the <code>sample()</code> method.</p>
<p>On the other hand, when you do not set the <code>seed</code> argument, then, Spark will likely produce a different random sample of the original DataFrame every time you run the <code>sample()</code> method.</p>
</section>
</section>
<section id="managing-the-columns-of-your-dataframe" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="managing-the-columns-of-your-dataframe"><span class="header-section-number">5.7</span> Managing the columns of your DataFrame</h2>
<p>Sometimes, you need manage or transform the columns you have. For example, you might need to change the order of these columns, or, to delete/rename some of them. To do this, you can use the <code>select()</code> and <code>drop()</code> methods of your DataFrame.</p>
<p>The <code>select()</code> method works very similarly to the <code>SELECT</code> statement of SQL. You basically list all the columns you want to keep in your DataFrame, in the specific order you want.</p>
<div id="0675ddfb" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>  .select(</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'transferID'</span>, <span class="st">'datetimeTransfer'</span>,</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'clientNumber'</span>, <span class="st">'transferValue'</span></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>  )<span class="op">\</span></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+----------+-------------------+------------+-------------+
|transferID|   datetimeTransfer|clientNumber|transferValue|
+----------+-------------------+------------+-------------+
|  20223563|2022-12-31 14:00:24|        5516|      7794.31|
|  20223562|2022-12-31 10:32:07|        4965|       7919.0|
|  20223561|2022-12-31 07:37:02|        4608|       5603.0|
|  20223560|2022-12-31 07:35:05|        1121|      4365.22|
|  20223559|2022-12-31 02:53:44|        1121|       4620.0|
+----------+-------------------+------------+-------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<section id="renaming-your-columns" class="level3" data-number="5.7.1">
<h3 data-number="5.7.1" class="anchored" data-anchor-id="renaming-your-columns"><span class="header-section-number">5.7.1</span> Renaming your columns</h3>
<p>Realize in the example above, that the column names can be delivered directly as strings to <code>select()</code>. This makes life pretty easy, but, it does not give you extra options.</p>
<p>For example, you might want to rename some of the columns, and, to do this, you need to use the <code>alias()</code> method from <code>Column</code> class. Since this is a method from <code>Column</code> class, you need to use it after a <code>col()</code> or <code>column()</code> function, or, after a column name using the dot operator.</p>
<div id="fef192be" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>  .select(</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'datetimeTransfer'</span>,</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">'transferID'</span>).alias(<span class="st">'ID_of_transfer'</span>),</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>    transf.clientNumber.alias(<span class="st">'clientID'</span>)</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>  )<span class="op">\</span></span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------------------+--------------+--------+
|   datetimeTransfer|ID_of_transfer|clientID|
+-------------------+--------------+--------+
|2022-12-31 14:00:24|      20223563|    5516|
|2022-12-31 10:32:07|      20223562|    4965|
|2022-12-31 07:37:02|      20223561|    4608|
|2022-12-31 07:35:05|      20223560|    1121|
|2022-12-31 02:53:44|      20223559|    1121|
+-------------------+--------------+--------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>By using this <code>alias()</code> method, you can rename multiple columns within a single <code>select()</code> call. However, you can use the <code>withColumnRenamed()</code> method to rename just a single column of your DataFrame. The first argument of this method, is the current name of this column, and, the second argument, is the new name of this column.</p>
<div id="1de5774f" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>  .withColumnRenamed(<span class="st">'clientNumber'</span>, <span class="st">'clientID'</span>)<span class="op">\</span></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+--------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientID|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+--------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-12-31|2022-12-31 14:00:24|    5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
|  2022-12-31|2022-12-31 10:32:07|    4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|
|  2022-12-31|2022-12-31 07:37:02|    4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|  2022-12-31|2022-12-31 07:35:05|    1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|  2022-12-31|2022-12-31 02:53:44|    1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|
+------------+-------------------+--------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
</section>
<section id="dropping-unnecessary-columns" class="level3" data-number="5.7.2">
<h3 data-number="5.7.2" class="anchored" data-anchor-id="dropping-unnecessary-columns"><span class="header-section-number">5.7.2</span> Dropping unnecessary columns</h3>
<p>In some cases, your DataFrame just have too many columns and you just want to eliminate a few of them. In a situation like this, you can list the columns you want to drop from your DataFrame, inside the <code>drop()</code> method, like this:</p>
<div id="8270e049" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>  .drop(<span class="st">'dateTransfer'</span>, <span class="st">'clientNumber'</span>)<span class="op">\</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|   datetimeTransfer|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+-------------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|2022-12-31 14:00:24|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|
|2022-12-31 10:32:07|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|
|2022-12-31 07:37:02|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|
|2022-12-31 07:35:05|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|
|2022-12-31 02:53:44|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|
+-------------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
</section>
<section id="sec-cast-column-type" class="level3" data-number="5.7.3">
<h3 data-number="5.7.3" class="anchored" data-anchor-id="sec-cast-column-type"><span class="header-section-number">5.7.3</span> Casting columns to a different data type</h3>
<p>Spark try to do its best when guessing which is correct data type for the columns of your DataFrame. But, obviously, Spark can get it wrong, and, you end up deciding by your own which data type to use for a specific column.</p>
<p>To explicit transform a column to a specific data type, you can use <code>cast()</code> or <code>astype()</code> methods inside <code>select()</code>. The <code>astype()</code> method is just an alias to <code>cast()</code>. This <code>cast()</code> method is very similar to the <code>CAST()</code> function in SQL, and belongs to the <code>Column</code> class, so, you should always use it after a column name with the dot operator, or, a <code>col()</code>/<code>column()</code> function:</p>
<div id="34b26880" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>  .select(</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'transferValue'</span>,</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">'transferValue'</span>).cast(<span class="st">'long'</span>).alias(<span class="st">'value_as_integer'</span>),</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>    transf.transferValue.cast(<span class="st">'boolean'</span>).alias(<span class="st">'value_as_boolean'</span>)</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>  )<span class="op">\</span></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------------+----------------+----------------+
|transferValue|value_as_integer|value_as_boolean|
+-------------+----------------+----------------+
|      7794.31|            7794|            true|
|       7919.0|            7919|            true|
|       5603.0|            5603|            true|
|      4365.22|            4365|            true|
|       4620.0|            4620|            true|
+-------------+----------------+----------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>To use <code>cast()</code> or <code>astype()</code> methods, you give the name of the data type (as a string) to which you want to cast the column. The main available data types to <code>cast()</code> or <code>astype()</code> are:</p>
<ul>
<li><code>'string'</code>: correspond to <code>StringType()</code>;</li>
<li><code>'int'</code>: correspond to <code>IntegerType()</code>;</li>
<li><code>'long'</code>: correspond to <code>LongType()</code>;</li>
<li><code>'double'</code>: correspond to <code>DoubleType()</code>;</li>
<li><code>'date'</code>: correspond to <code>DateType()</code>;</li>
<li><code>'timestamp'</code>: correspond to <code>TimestampType()</code>;</li>
<li><code>'boolean'</code>: correspond to <code>BooleanType()</code>;</li>
<li><code>'array'</code>: correspond to <code>ArrayType()</code>;</li>
<li><code>'dict'</code>: correspond to <code>MapType()</code>;</li>
</ul>
</section>
<section id="you-can-add-new-columns-with-select" class="level3" data-number="5.7.4">
<h3 data-number="5.7.4" class="anchored" data-anchor-id="you-can-add-new-columns-with-select"><span class="header-section-number">5.7.4</span> You can add new columns with <code>select()</code></h3>
<p>When I said that <code>select()</code> works in the same way as the <code>SELECT</code> statement of SQL, I also meant that you can use <code>select()</code> to select columns that do not currently exist in your DataFrame, and add them to the final result.</p>
<p>For example, I can select a new column (called <code>by_1000</code>) containing <code>value</code> divided by 1000, like this:</p>
<div id="bc1a6c6f" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>  .select(</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'transferValue'</span>,</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">'transferValue'</span>) <span class="op">/</span> <span class="dv">1000</span>).alias(<span class="st">'by_1000'</span>)</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>  )<span class="op">\</span></span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+-------------+-------+
|transferValue|by_1000|
+-------------+-------+
|      7794.31|7.79431|
|       7919.0|  7.919|
|       5603.0|  5.603|
|      4365.22|4.36522|
|       4620.0|   4.62|
+-------------+-------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>This <code>by_1000</code> column do not exist in <code>transf</code> DataFrame. It was calculated and added to the final result by <code>select()</code>. The formula <code>col('transferValue') / 1000</code> is the equation that defines what this <code>by_1000</code> column is, or, how it should be calculated.</p>
<p>Besides that, <code>select()</code> provides a useful shortcut to reference all the columns of your DataFrame. That is, the star symbol (<code>*</code>) from the <code>SELECT</code> statement in SQL. This shortcut is very useful when you want to maintain all columns, and, add a new column, at the same time.</p>
<p>In the example below, we are adding the same <code>by_1000</code> column, however, we are bringing all the columns of <code>transf</code> together.</p>
<div id="c52cadf6" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>  .select(</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'*'</span>,</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">'transferValue'</span>) <span class="op">/</span> <span class="dv">1000</span>).alias(<span class="st">'by_1000'</span>)</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>  )<span class="op">\</span></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+-------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|by_1000|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+-------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|7.79431|
|  2022-12-31|2022-12-31 10:32:07|        4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|  7.919|
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|  5.603|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|4.36522|
|  2022-12-31|2022-12-31 02:53:44|        1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|   4.62|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+-------+
only showing top 5 rows
</code></pre>
</div>
</div>
</section>
</section>
<section id="calculating-or-adding-new-columns-to-your-dataframe" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="calculating-or-adding-new-columns-to-your-dataframe"><span class="header-section-number">5.8</span> Calculating or adding new columns to your DataFrame</h2>
<p>Although you can add new columns with <code>select()</code>, this method is not specialized to do that. As consequence, when you want to add many new columns, it can become pretty annoying to write <code>select('*', new_column)</code> over and over again. That is why <code>pyspark</code> provides a special method called <code>withColumn()</code>.</p>
<p>This method has two arguments. First, is the name of the new column. Second, is the formula (or the equation) that represents this new column. As an example, I could reproduce the same <code>by_1000</code> column like this:</p>
<div id="80990274" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>  .withColumn(<span class="st">'by_1000'</span>, col(<span class="st">'transferValue'</span>) <span class="op">/</span> <span class="dv">1000</span>)<span class="op">\</span></span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+-------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|by_1000|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+-------+
|  2022-12-31|2022-12-31 14:00:24|        5516|      7794.31|          zing ƒ|  20223563|       NULL|                   33|                 4078|               72424-2|7.79431|
|  2022-12-31|2022-12-31 10:32:07|        4965|       7919.0|          zing ƒ|  20223562|       NULL|                  421|                 1979|               36441-5|  7.919|
|  2022-12-31|2022-12-31 07:37:02|        4608|       5603.0|        dollar $|  20223561|       NULL|                  666|                 4425|               41323-1|  5.603|
|  2022-12-31|2022-12-31 07:35:05|        1121|      4365.22|        dollar $|  20223560|       NULL|                  666|                 2400|               74120-4|4.36522|
|  2022-12-31|2022-12-31 02:53:44|        1121|       4620.0|        dollar $|  20223559|       NULL|                  421|                 1100|               39830-0|   4.62|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+-------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>A lot of the times we use the functions from <code>pyspark.sql.functions</code> module to produce such formulas used by <code>withColumn()</code>. You can checkout the complete list of functions present in this module, by visiting the official documentation of <code>pyspark</code><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p>You will see a lot more examples of formulas and uses of <code>withColumn()</code> throughout this book. For now, I just want you to know that <code>withColumn()</code> is a method that adds a new column to your DataFrame. The first argument is the name of the new column, and, the second argument is the calculation formula of this new column.</p>
</section>
<section id="sorting-rows-of-your-dataframe" class="level2" data-number="5.9">
<h2 data-number="5.9" class="anchored" data-anchor-id="sorting-rows-of-your-dataframe"><span class="header-section-number">5.9</span> Sorting rows of your DataFrame</h2>
<p>Spark, or, <code>pyspark</code>, provides the <code>orderBy()</code> and <code>sort()</code> DataFrame method to sort rows. They both work the same way: you just give the name of the columns that Spark will use to sort the rows.</p>
<p>In the example below, Spark will sort <code>transf</code> according to the values in the <code>transferValue</code> column. By default, Spark uses an ascending order while sorting your rows.</p>
<div id="90e1d649" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>  .orderBy(<span class="st">'transferValue'</span>)<span class="op">\</span></span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-07-22|2022-07-22 16:06:25|        3795|         60.0|        dollar $|  20222533|       NULL|                  290|                 1100|               39925-1|
|  2022-05-09|2022-05-09 14:02:15|        3284|        104.0|        dollar $|  20222033|       NULL|                  666|                 2231|               74766-2|
|  2022-09-16|2022-09-16 20:35:40|        3294|       129.09|          zing ƒ|  20222896|       NULL|                  290|                 3321|               60867-9|
|  2022-12-18|2022-12-18 08:45:30|        1297|       142.66|        dollar $|  20223467|       NULL|                  421|                 5420|               43088-1|
|  2022-08-20|2022-08-20 09:27:55|        2727|        160.0|        dollar $|  20222724|       NULL|                   33|                 1002|               75581-5|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>Just to be clear, you can use the combination between multiple columns to sort your rows. Just give the name of each column (as strings) separated by commas. In the example below, Spark will sort the rows according to <code>clientNumber</code> column first, then, is going to sort the rows of each <code>clientNumber</code> according to <code>transferValue</code> column.</p>
<div id="eaece40e" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>  .orderBy(<span class="st">'clientNumber'</span>, <span class="st">'transferValue'</span>)<span class="op">\</span></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-03-30|2022-03-30 11:57:22|        1121|        461.0|          euro €|  20221738|       NULL|                  666|                 6552|               35568-9|
|  2022-05-23|2022-05-23 11:51:02|        1121|       844.66| british pound £|  20222127|       NULL|                  421|                 1002|               32340-0|
|  2022-08-24|2022-08-24 13:51:30|        1121|      1046.93|          euro €|  20222748|       NULL|                  421|                 6317|               38887-3|
|  2022-09-23|2022-09-23 19:49:19|        1121|       1327.0| british pound £|  20222938|       NULL|                  290|                 5420|               77350-1|
|  2022-06-25|2022-06-25 17:07:08|        1121|       1421.0|        dollar $|  20222361|       NULL|                  290|                 9921|               77258-7|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>If you want to use a descending order in a specific column, you need to use the <code>desc()</code> method from <code>Column</code> class. In the example below, Spark will sort the rows according to <code>clientNumber</code> column using an ascending order. However, it will use the values from <code>transferValue</code> column in a descending order to sort the rows in each <code>clientNumber</code>.</p>
<div id="a66cb93f" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>transf<span class="op">\</span></span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>  .orderBy(<span class="st">'clientNumber'</span>, col(<span class="st">'transferValue'</span>).desc())<span class="op">\</span></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|dateTransfer|   datetimeTransfer|clientNumber|transferValue|transferCurrency|transferID|transferLog|destinationBankNumber|destinationBankBranch|destinationBankAccount|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
|  2022-08-18|2022-08-18 13:57:12|        1121|     11490.37|          zing ƒ|  20222712|       NULL|                  421|                 2400|               61244-9|
|  2022-11-05|2022-11-05 08:00:37|        1121|     10649.59|        dollar $|  20223197|       NULL|                  421|                 3321|               40011-2|
|  2022-05-17|2022-05-17 10:27:05|        1121|     10471.23| british pound £|  20222086|       NULL|                  666|                 8521|               26534-1|
|  2022-05-15|2022-05-15 00:25:49|        1121|      10356.0|        dollar $|  20222075|       NULL|                   33|                 1979|               28234-7|
|  2022-06-10|2022-06-09 23:51:39|        1121|      10142.0|        dollar $|  20222241|       NULL|                   33|                 2400|               36594-6|
+------------+-------------------+------------+-------------+----------------+----------+-----------+---------------------+---------------------+----------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>This means that you can mix ascending orders with descending orders in <code>orderBy()</code>. Since the ascending order is the default, if you want to use a descending order in all of the columns, then, you need to apply the <code>desc()</code> method to all of them.</p>
</section>
<section id="calculating-aggregates" class="level2" data-number="5.10">
<h2 data-number="5.10" class="anchored" data-anchor-id="calculating-aggregates"><span class="header-section-number">5.10</span> Calculating aggregates</h2>
<p>To calculate aggregates of a Spark DataFrame we have two main paths: 1) we can use some standard DataFrame methods, like <code>count()</code> or <code>sum()</code>, to calculate a single aggregate; 2) or, we can use the <code>agg()</code> method to calculate multiple aggregates at the same time.</p>
<section id="using-standard-dataframe-methods" class="level3" data-number="5.10.1">
<h3 data-number="5.10.1" class="anchored" data-anchor-id="using-standard-dataframe-methods"><span class="header-section-number">5.10.1</span> Using standard DataFrame methods</h3>
<p>The Spark DataFrame class by itself provides a single aggregate method, which is <code>count()</code>. With this method, you can find out how many rows your DataFrame have. In the example below, we can see that <code>transf</code> have 2421 rows.</p>
<div id="276f8fb6" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>transf.count()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>2421</code></pre>
</div>
</div>
<p>However, if you have a <strong>grouped</strong> DataFrame (we will learn more about these objects very soon), <code>pyspark</code> provides some more aggregate methods, which are listed below:</p>
<ul>
<li><code>mean()</code>: calculate the average value of each numeric column;</li>
<li><code>sum()</code>: return the total sum of a column;</li>
<li><code>count()</code>: count the number of rows;</li>
<li><code>max()</code>: compute the maximum value of a column;</li>
<li><code>min()</code>: compute the minimum value of a column;</li>
</ul>
<p>This means that you can use any of the above methods after a <code>groupby()</code> call, to calculate aggregates <em>per group</em> in your Spark DataFrame. For now, lets forget about this “groupby” detail, and learn how to calculate different aggregates by using the <code>agg()</code> method.</p>
</section>
<section id="sec-agg-method" class="level3" data-number="5.10.2">
<h3 data-number="5.10.2" class="anchored" data-anchor-id="sec-agg-method"><span class="header-section-number">5.10.2</span> Using the <code>agg()</code> method</h3>
<p>With the <code>agg()</code> method, we can calculate many different aggregates at the same time. In this method, you should provide a expression that describes what aggregate measure you want to calculate.</p>
<p>In most cases, this “aggregate expression” will be composed of functions from the <code>pyspark.sql.functions</code> module. So, having familiarity with the functions present in this module will help you to compose the formulas of your aggregations in <code>agg()</code>.</p>
<p>In the example below, I am using the <code>sum()</code> and <code>mean()</code> functions from <code>pyspark.sql.functions</code> to calculate the total sum and the total mean of the <code>transferValue</code> column in the <code>transf</code> DataFrame. I am also using the <code>countDistinct()</code> function to calculate the number of distinct values in the <code>clientNumber</code> column.</p>
<div id="525f6819" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyspark.sql.functions <span class="im">as</span> F</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>transf.agg(</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>    F.<span class="bu">sum</span>(<span class="st">'transferValue'</span>).alias(<span class="st">'total_value'</span>),</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>    F.mean(<span class="st">'transferValue'</span>).alias(<span class="st">'mean_value'</span>),</span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>    F.countDistinct(<span class="st">'clientNumber'</span>).alias(<span class="st">'number_of_clients'</span>)</span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>  )<span class="op">\</span></span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>  .show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+--------------------+-----------------+-----------------+
|         total_value|       mean_value|number_of_clients|
+--------------------+-----------------+-----------------+
|1.5217690679999998E7|6285.704535315985|               26|
+--------------------+-----------------+-----------------+
</code></pre>
</div>
</div>
</section>
<section id="without-groups-we-calculate-a-aggregate-of-the-entire-dataframe" class="level3" data-number="5.10.3">
<h3 data-number="5.10.3" class="anchored" data-anchor-id="without-groups-we-calculate-a-aggregate-of-the-entire-dataframe"><span class="header-section-number">5.10.3</span> Without groups, we calculate a aggregate of the entire DataFrame</h3>
<p>When we do not define any group for the input DataFrame, <code>agg()</code> always produce a new DataFrame with one single row (like in the above example). This happens because we are calculating aggregates of the entire DataFrame, that is, a set of single values (or single measures) that summarizes (in some way) the entire DataFrame.</p>
<p>In the other hand, when we define groups in a DataFrame (by using the <code>groupby()</code> method), the calculations performed by <code>agg()</code> are made inside each group in the DataFrame. In other words, instead of summarizing the entire DataFrame, <code>agg()</code> will produce a set of single values that describes (or summarizes) each group in the DataFrame.</p>
<p>This means that each row in the resulting DataFrame describes a specific group in the original DataFrame, and, <code>agg()</code> usually produces a DataFrame with more than one single row when its calculations are performed by group. Because our DataFrames usually have more than one single group.</p>
</section>
<section id="sec-group-by" class="level3" data-number="5.10.4">
<h3 data-number="5.10.4" class="anchored" data-anchor-id="sec-group-by"><span class="header-section-number">5.10.4</span> Calculating aggregates per group in your DataFrame</h3>
<p>But how you define the groups inside your DataFrame? To do this, we use the <code>groupby()</code> and <code>groupBy()</code> methods. These methods are both synonymous (they do the same thing).</p>
<p>These methods, produce a <strong>grouped</strong> DataFrame as a result, or, in more technical words, a object of class <code>pyspark.sql.group.GroupedData</code>. You just need to provide, inside this <code>groupby()</code> method, the name of the columns that define (or “mark”) your groups.</p>
<p>In the example below, I am creating a grouped DataFrame per client defined in the <code>clientNumber</code> column. This means that each distinct value in the <code>clientNumber</code> column defines a different group in the DataFrame.</p>
<div id="937834af" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>transf_per_client <span class="op">=</span> transf.groupBy(<span class="st">'clientNumber'</span>)</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>transf_per_client</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>GroupedData[grouping expressions: [clientNumber], value: [dateTransfer: date, datetimeTransfer: timestamp ... 8 more fields], type: GroupBy]</code></pre>
</div>
</div>
<p>At first, it appears that nothing has changed. But the <code>groupBy()</code> method always returns a new object of class <code>pyspark.sql.group.GroupedData</code>. As a consequence, we can no longer use some of the DataFrame methods that we used before, like the <code>show()</code> method to see the DataFrame.</p>
<p>That’s ok, because we usually do not want to keep this grouped DataFrame for much time. This grouped DataFrame is just a passage (or a bridge) to the result we want, which is, to calculate aggregates <strong>per group</strong> of the DataFrame.</p>
<p>As an example, I can use the <code>max()</code> method, to find out which is the highest value that each user have tranfered, like this:</p>
<div id="e0946674" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>transf_per_client<span class="op">\</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>  .<span class="bu">max</span>(<span class="st">'transferValue'</span>)<span class="op">\</span></span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+------------------+
|clientNumber|max(transferValue)|
+------------+------------------+
|        1217|           12601.0|
|        2489|          12644.56|
|        3284|          12531.84|
|        4608|          10968.31|
|        1297|           11761.0|
+------------+------------------+
only showing top 5 rows
</code></pre>
</div>
</div>
<p>Remember that, by using standard DataFrame methods (like <code>max()</code> in the example above) we can calculate only a single aggregate value. But, with <code>agg()</code> we can calculate more than one aggregate value at the same time. Since our <code>transf_per_client</code> object is a <strong>grouped</strong> DataFrame, <code>agg()</code> will calculate these aggregates per group.</p>
<p>As an example, if I apply <code>agg()</code> with the exact same expressions exposed on <a href="#sec-agg-method" class="quarto-xref"><span>Section 5.10.2</span></a> with the <code>transf_per_client</code> DataFrame, instead of a DataFrame with one single row, I get a new DataFrame with nine rows. In each row, I have the total and mean values for a specific user in the input DataFrame.</p>
<div id="5ff2b969" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>transf_per_client<span class="op">\</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>  .agg(</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>    F.<span class="bu">sum</span>(<span class="st">'transferValue'</span>).alias(<span class="st">'total_value'</span>),</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>    F.mean(<span class="st">'transferValue'</span>).alias(<span class="st">'mean_value'</span>)</span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a>  )<span class="op">\</span></span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a>  .show(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>+------------+-----------------+------------------+
|clientNumber|      total_value|        mean_value|
+------------+-----------------+------------------+
|        1217|575218.2099999998| 6185.142043010751|
|        2489|546543.0900000001| 6355.152209302327|
|        3284|581192.5700000001| 6054.089270833334|
|        4608|        448784.44| 6233.117222222222|
|        1297|594869.6699999999|6196.5590624999995|
+------------+-----------------+------------------+
only showing top 5 rows
</code></pre>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-chambers2018" class="csl-entry" role="listitem">
Chambers, Bill, and Matei Zaharia. 2018. <em>Spark: The Definitive Guide: Big Data Processing Made Simple</em>. Sebastopol, CA: O’Reilly Media.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p><a href="https://github.com/pedropark99/Introd-pyspark/tree/main/Data" class="uri">https://github.com/pedropark99/Introd-pyspark/tree/main/Data</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#functions" class="uri">https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#functions</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../Chapters/04-columns.html" class="pagination-link" aria-label="Introducing the `Column` class">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing the <code>Column</code> class</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../Chapters/07-import.html" class="pagination-link" aria-label="Importing data to Spark">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Importing data to Spark</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>